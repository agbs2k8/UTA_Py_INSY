{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PyPDF2 #Reads PDF Files\n",
    "import ujson\n",
    "import hashlib\n",
    "import pickle\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Master Repository of Content\n",
    "### Starting from the complete PDF Library being downloaded and the binary file of each PDF document hashed and appended to a JSON object for that file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36549\n",
      "5546\n"
     ]
    }
   ],
   "source": [
    "#Recreate complete list of JSON objects that were created:\n",
    "working_uid_list = []\n",
    "working_hash_dict = {}\n",
    "\n",
    "for x in range (100, 37871):\n",
    "    try:\n",
    "        with open ('D:\\BSA_PDF_Files\\JSON\\BSA_{}.json'.format(x),'r') as j:\n",
    "            temp_hash = ujson.load(j)[\"Hash\"]\n",
    "            working_uid_list.append('BSA_{}'.format(x))\n",
    "            if temp_hash in working_hash_dict:\n",
    "                working_hash_dict[temp_hash].append('BSA_{}'.format(x))\n",
    "            else:\n",
    "                working_hash_dict.update({temp_hash:['BSA_{}'.format(x)]})\n",
    "    except:\n",
    "        continue\n",
    "print(len(working_uid_list))\n",
    "print(len(working_hash_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertPDF2String(path):\n",
    "    content = \"\"\n",
    "    # load pdf file\n",
    "    pdf = PyPDF2.PdfFileReader(file(path,\"rb\"))\n",
    "    if pdf.isEncrypted: \n",
    "        try: pdf.decrypt('')\n",
    "        except: print(\"Attempted decrpytion failed on UID: \"+uid)\n",
    "    # iterate pages\n",
    "    for i in range(0, pdf.getNumPages()):\n",
    "        # extract the text from each page\n",
    "        try: content += pdf.getPage(i).extractText() + \" \\n\"\n",
    "        except: continue\n",
    "    # collapse whitespaces\n",
    "    content = \" \".join(content.replace(u\"\\xa0\", \" \").split()).encode('utf-8')\n",
    "    return (content) #.encode('utf-8')\n",
    "\n",
    "#Append textual content to dictionary for ecah unique PDF file\n",
    "def contentReadAndAppend(uid):\n",
    "    try: \n",
    "        with open('D:\\BSA_PDF_Files\\JSON\\\\'+uid+'.json', 'r') as i:\n",
    "            uid_dict_check = ujson.load(i)\n",
    "            old_content = uid_dict_check[\"Content\"]\n",
    "    except: \n",
    "        old_content = None\n",
    "    if old_content is None:\n",
    "        content = convertPDF2String('D:\\BSA_PDF_Files\\\\'+uid+'.pdf')\n",
    "        with open('D:\\BSA_PDF_Files\\JSON\\\\'+uid+'.json', 'r') as j: #open JSON for the file in question\n",
    "            uid_dict = ujson.load(j)\n",
    "        uid_dict.update({\"Content\":content})\n",
    "        with open('D:\\BSA_PDF_Files\\JSON\\\\'+uid+'.json', 'w') as k:\n",
    "            ujson.dump(uid_dict,k,indent=4)\n",
    "\n",
    "def addPageNumbers(uid):\n",
    "    try:\n",
    "        with open ('D:\\BSA_PDF_Files\\JSON\\\\'+uid+'.json','r') as j:\n",
    "            uid_dict_check = ujson.load(i)\n",
    "            old_pgn = uid_dict_check[\"Pages\"]\n",
    "    except:\n",
    "        old_pgn = None\n",
    "    if old_pgn is None:\n",
    "        tempPdf = PyPDF2.PdfFileReader(file('D:\\BSA_PDF_Files\\\\'+uid+'.pdf','rb'))\n",
    "        if tempPdf.isEncrypted: \n",
    "                    try: tempPdf.decrypt('')\n",
    "                    except: print(\"Attempted decrpytion failed on uid: \"+uid)\n",
    "        pageNumbers = tempPdf.getNumPages()\n",
    "        #print (pageNumbers)\n",
    "        with open('D:\\BSA_PDF_Files\\JSON\\\\'+uid+'.json', 'r') as k:\n",
    "            uid_dict = ujson.load(k)\n",
    "        uid_dict.update({\"Pages\":pageNumbers})\n",
    "        with open('D:\\BSA_PDF_Files\\JSON\\\\'+uid+'.json', 'w') as l:\n",
    "            ujson.dump(uid_dict,l,indent=4)\n",
    "\n",
    "for uid in working_uid_list:\n",
    "    try:contentReadAndAppend(uid)\n",
    "    except:print(\"Content Error on UID: \"+uid)\n",
    "    try:addPageNumbers(uid)\n",
    "    except:print(\"PageNum Error on UID: \"+uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222\n"
     ]
    }
   ],
   "source": [
    "content_hash_dict = {}\n",
    "\n",
    "def create_content_hash(uid):\n",
    "    global content_hash_dict\n",
    "    try:\n",
    "        with open ('D:\\BSA_PDF_Files\\JSON\\\\'+uid+'.json','r') as j:    \n",
    "            uid_dict = ujson.load(j)\n",
    "        uid_content = uid_dict['Content']\n",
    "        \n",
    "    except:\n",
    "        uid_content = None    \n",
    "    #print(uid_content)\n",
    "    \n",
    "    if uid_content is not None: \n",
    "        try:\n",
    "            tempHash = hashlib.sha1(uid_content).hexdigest()\n",
    "        except:\n",
    "            decoded_content = unidecode(uid_content)\n",
    "            tempHash = hashlib.sha1(decoded_content).hexdigest()\n",
    "        #print(tempHash)\n",
    "        if tempHash in content_hash_dict:\n",
    "            content_hash_dict[tempHash].append(uid) #add new has to global dictionary\n",
    "        else:\n",
    "            content_hash_dict.update({tempHash:[uid]}) #append UID to an existing list of UIDs for that hash value\n",
    "        \n",
    "        uid_dict.update({\"Content_Hash\":tempHash})\n",
    "\n",
    "    with open('D:\\BSA_PDF_Files\\JSON\\\\'+uid+'.json','w') as k:\n",
    "        ujson.dump(uid_dict,k,indent=4)\n",
    "\n",
    "\n",
    "for uid in working_uid_list:\n",
    "    create_content_hash(uid)\n",
    "        \n",
    "print(len(content_hash_dict))\n",
    "\n",
    "with open('D:\\BSA_PDF_Files\\JSON\\Content_Hash_Dict.json','w') as o:\n",
    "    ujson.dump(content_hash_dict,o,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open (\"working_uid_list.pickle\",\"w\") as u:\n",
    "    pickle.dump(working_uid_list, u)\n",
    "with open (\"working_hash_dict.pickle\",\"w\") as v:\n",
    "    pickle.dump(working_hash_dict, v)\n",
    "with open (\"content_hash_dict.pickle\",\"w\") as x:\n",
    "    pickle.dump(content_hash_dict, x)\n",
    "with open('bin_hash_url.pickle','w') as z:\n",
    "    pickle.dump(bin_hash_url,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_uid_list =  pickle.load(open('working_uid_list.pickle','r'))\n",
    "working_hash_dict = pickle.load(open('working_hash_dict.pickle','r'))\n",
    "content_hash_dict = pickle.load(open('content_hash_dict.pickle','r'))\n",
    "bin_hash_url = pickle.load(open('bin_hash_url.pickle','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36549\n",
      "5546\n",
      "4221\n",
      "5546\n"
     ]
    }
   ],
   "source": [
    "print(len(working_uid_list))\n",
    "print(len(working_hash_dict))\n",
    "print(len(content_hash_dict))\n",
    "print(len(bin_hash_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Complete\n"
     ]
    }
   ],
   "source": [
    "bin_hash_url = {}\n",
    "for bin_hash in working_hash_dict:\n",
    "    \n",
    "    uids = working_hash_dict[bin_hash]\n",
    "    urls = []\n",
    "    for uid in uids:\n",
    "        with open ('D:\\BSA_PDF_Files\\JSON\\\\'+uid+'.json','r') as j:    \n",
    "            urls.append(ujson.load(j)[\"URL\"])\n",
    "    bin_hash_url.update({bin_hash:urls})\n",
    "with open (\"bin_hash_url.pickle\",\"w\") as d:\n",
    "    pickle.dump(bin_hash_url, d)\n",
    "\n",
    "print(\"Operation Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Hash_to_URLs.json','w') as f:\n",
    "    ujson.dump(bin_hash_url,f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to initialize and use MongoDB for the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "# Connect to the mongo local database\n",
    "connection = MongoClient()\n",
    "db = connection.bsa_files\n",
    "collection = db.bsa_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)\n",
      "\n",
      "Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'bsa_files')\n",
      "\n",
      "<bound method MongoClient.database_names of MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)>\n",
      "\n",
      "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'bsa_files'), u'bsa_files')\n",
      "\n",
      "<bound method Database.collection_names of Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'bsa_files')>\n"
     ]
    }
   ],
   "source": [
    "print(connection)\n",
    "print\n",
    "print(db)\n",
    "print\n",
    "print(connection.database_names)\n",
    "print\n",
    "print(collection)\n",
    "print\n",
    "print(db.collection_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'Domain': u'adventure.oa-bsa.org', u'Hash': u'bd1555e13f710c5ebf508349bc97fd87cec1e69f', u'UID': u'BSA_101', u'URL': u'http://adventure.oa-bsa.org/files/flyers/GENERAL_OAHA_FLYER.pdf', u'File_Name': u'GENERAL_OAHA_FLYER.pdf', u'Content': u'ORDER OF THE ARROW HIGH ADVENTURE ADVENTURE.OA - BSA.ORG TRAIL CREW WILDERNESS VOYAGE CANADIAN ODYSSEY OCEAN ADVENTURE SUMMIT EXPERIENCE Requirements: Be at least 16 years old by the time your program starts but not yet 21 by its conclusion(14 - 17 for Summit Experience) Be active in the BSA and a local OA Lodge See applications for height and weight restrictions', u'Content_Hash': u'83602de48c5d4ce405560dbaebeff9a3091acbe3', u'File_Size': 400338, u'Folder': u'flyers', u'Pages': 1, u'Metadata': {u'/Creator': u'Microsoft\\xae Publisher 2013', u'/ModDate': u\"D:20150503103301-05'00'\", u'/Producer': u'Microsoft\\xae Publisher 2013', u'/CreationDate': u\"D:20150503103301-05'00'\", u'/Author': u'sean ferrier'}}\n"
     ]
    }
   ],
   "source": [
    "with open('D:\\BSA_PDF_Files\\JSON\\BSA_101.json','r') as j:\n",
    "    test_file = ujson.load(j)\n",
    "print(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x7987510>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.insert_one(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'Domain': u'adventure.oa-bsa.org', u'Hash': u'bd1555e13f710c5ebf508349bc97fd87cec1e69f', u'UID': u'BSA_101', u'URL': u'http://adventure.oa-bsa.org/files/flyers/GENERAL_OAHA_FLYER.pdf', u'File_Name': u'GENERAL_OAHA_FLYER.pdf', u'Pages': 1, u'Content': u'ORDER OF THE ARROW HIGH ADVENTURE ADVENTURE.OA - BSA.ORG TRAIL CREW WILDERNESS VOYAGE CANADIAN ODYSSEY OCEAN ADVENTURE SUMMIT EXPERIENCE Requirements: Be at least 16 years old by the time your program starts but not yet 21 by its conclusion(14 - 17 for Summit Experience) Be active in the BSA and a local OA Lodge See applications for height and weight restrictions', u'File_Size': 400338, u'Content_Hash': u'83602de48c5d4ce405560dbaebeff9a3091acbe3', u'_id': ObjectId('582cbfb88726e30d949a9815'), u'Folder': u'flyers', u'Metadata': {u'/CreationDate': u\"D:20150503103301-05'00'\", u'/Author': u'sean ferrier', u'/Producer': u'Microsoft\\xae Publisher 2013', u'/Creator': u'Microsoft\\xae Publisher 2013', u'/ModDate': u\"D:20150503103301-05'00'\"}}\n"
     ]
    }
   ],
   "source": [
    "retrieved_file = collection.find_one()\n",
    "print(retrieved_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "***************************************************************************\n"
     ]
    }
   ],
   "source": [
    "#retrieved_file = collection.find_one({'UID':u'BSA_{}'.format(3702)})\n",
    "retrieved_file = collection.find_one({'Language':'English'})\n",
    "print(retrieved_file)\n",
    "print('*'*75)\n",
    "#print(unidecode(retrieved_file['Content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_JSON_to_mongo(uid):\n",
    "    with open('D:\\BSA_PDF_Files\\JSON\\{}.json'.format(uid),'r') as j:\n",
    "        collection.insert_one(ujson.load(j))\n",
    "\n",
    "for uid in working_uid_list:\n",
    "    write_JSON_to_mongo(uid)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
